{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYKWe_nZ4jrT",
        "outputId": "33602271-19c3-4ce6-94f0-37dcac6f81c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-ncqE2ZMW6qj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "import torch.onnx\n",
        "import onnx\n",
        "import onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kMhVMdvI90s4"
      },
      "outputs": [],
      "source": [
        "D_in, H, D_out = 10, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DusYFZpb94Eu",
        "outputId": "0f5afdb6-0913-49b1-9bc0-ec40ba8d409c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "outputs = model(torch.randn(64, 10))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT0s4PZ0AoT7",
        "outputId": "ce7a5d13-1fa8-47b7-91c2-1c72bdda5783"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17995, 10), (17995,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df = pd.read_csv('riceClassification.csv')\n",
        "X = df.iloc[:, :10]\n",
        "Y = df.iloc[:, -1]\n",
        "\n",
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oZbwuYS7Crji"
      },
      "outputs": [],
      "source": [
        "x_2 = np.array(X)\n",
        "y_2 = np.array(Y)\n",
        "\n",
        "scaler = StandardScaler().fit(x_2)\n",
        "x_2_normalized = scaler.transform(x_2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_2_normalized, y_2, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5j7AkggUGLL5"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clase Dataset\n"
      ],
      "metadata": {
        "id": "334aqH-_cI5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RiceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.Y = torch.from_numpy(Y).long()\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        return self.X[ix], self.Y[ix]"
      ],
      "metadata": {
        "id": "ti_Vm0MdZnfA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = RiceDataset(X_train, y_train)\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaBLRvdncyQN",
        "outputId": "866a5f13-6de8-4f27-a89e-4b36d197652c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14396"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skpk7uxRHeC2",
        "outputId": "1cd73e88-c6ec-487e-ad93-dd8eb468dcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 Loss 0.93312\n",
            "Epoch 200/1000 Loss 0.77380\n",
            "Epoch 300/1000 Loss 0.67042\n",
            "Epoch 400/1000 Loss 0.59080\n",
            "Epoch 500/1000 Loss 0.52804\n",
            "Epoch 600/1000 Loss 0.47871\n",
            "Epoch 700/1000 Loss 0.43944\n",
            "Epoch 800/1000 Loss 0.40747\n",
            "Epoch 900/1000 Loss 0.38090\n",
            "Epoch 1000/1000 Loss 0.35843\n"
          ]
        }
      ],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=0.3)\n",
        "\n",
        "epochs = 1000\n",
        "log_each = 100\n",
        "checkpoint_each = 20\n",
        "l = []\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "    y_pred = model(dataset.X)\n",
        "    loss = loss_fn(y_pred, dataset.Y)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % log_each == 0:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "    if e % checkpoint_each == 0:\n",
        "        torch.save({\n",
        "            'epoch': e,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "        }, f\"checkpoint_epoch_{e}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_J8A2dCJNyk",
        "outputId": "afb38920-5148-482b-a556-235efdcb40be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9680466796332314"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clase DataLoader\n"
      ],
      "metadata": {
        "id": "SvMRIvsecnJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=62, shuffle=True)"
      ],
      "metadata": {
        "id": "DJ2JFCNBc3RA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=0.3)\n",
        "\n",
        "epochs = 1000\n",
        "log_each = 100\n",
        "l = []\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, targets in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    l.append(epoch_loss / len(dataloader))  # Average loss for the epoch\n",
        "\n",
        "    if e % log_each == 0:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yydF9fDPdjxk",
        "outputId": "c5a1c0b8-fd44-422d-b2b1-b9a34f8a0a91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 Loss 0.10331\n",
            "Epoch 200/1000 Loss 0.09236\n",
            "Epoch 300/1000 Loss 0.08699\n",
            "Epoch 400/1000 Loss 0.08321\n",
            "Epoch 500/1000 Loss 0.08018\n",
            "Epoch 600/1000 Loss 0.07772\n",
            "Epoch 700/1000 Loss 0.07564\n",
            "Epoch 800/1000 Loss 0.07401\n",
            "Epoch 900/1000 Loss 0.07249\n",
            "Epoch 1000/1000 Loss 0.07110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluar Dataloader"
      ],
      "metadata": {
        "id": "6Xzst-3MfFFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)  # Get the predicted classes\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    return accuracy\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have `model` and `test_dataloader` defined\n",
        "accuracy = evaluate_model(model, dataloader)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y-qv74HfDID",
        "outputId": "2bab4722-54c3-40f1-a26c-08dcfd42aab6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9791608780216727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hipUzCMF096g"
      },
      "source": [
        "Cargar todo los checkpoints basados en los epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oui7Ws1ezwES",
        "outputId": "dbfad42c-2d4a-46ea-ae23-f16b7962ec9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at epoch 20: 0.6149\n",
            "Accuracy at epoch 40: 0.6935\n",
            "Accuracy at epoch 60: 0.7599\n",
            "Accuracy at epoch 80: 0.8047\n",
            "Accuracy at epoch 100: 0.8266\n",
            "Accuracy at epoch 120: 0.8441\n",
            "Accuracy at epoch 140: 0.7858\n",
            "Accuracy at epoch 160: 0.7327\n",
            "Accuracy at epoch 180: 0.7755\n",
            "Accuracy at epoch 200: 0.7833\n",
            "Accuracy at epoch 220: 0.7899\n",
            "Accuracy at epoch 240: 0.8030\n",
            "Accuracy at epoch 260: 0.8152\n",
            "Accuracy at epoch 280: 0.8266\n",
            "Accuracy at epoch 300: 0.8363\n",
            "Accuracy at epoch 320: 0.8491\n",
            "Accuracy at epoch 340: 0.8572\n",
            "Accuracy at epoch 360: 0.8661\n",
            "Accuracy at epoch 380: 0.8772\n",
            "Accuracy at epoch 400: 0.8858\n",
            "Accuracy at epoch 420: 0.8916\n",
            "Accuracy at epoch 440: 0.8997\n",
            "Accuracy at epoch 460: 0.9072\n",
            "Accuracy at epoch 480: 0.9147\n",
            "Accuracy at epoch 500: 0.9178\n",
            "Accuracy at epoch 520: 0.9239\n",
            "Accuracy at epoch 540: 0.9280\n",
            "Accuracy at epoch 560: 0.9314\n",
            "Accuracy at epoch 580: 0.9355\n",
            "Accuracy at epoch 600: 0.9397\n",
            "Accuracy at epoch 620: 0.9439\n",
            "Accuracy at epoch 640: 0.9469\n",
            "Accuracy at epoch 660: 0.9500\n",
            "Accuracy at epoch 680: 0.9514\n",
            "Accuracy at epoch 700: 0.9539\n",
            "Accuracy at epoch 720: 0.9544\n",
            "Accuracy at epoch 740: 0.9564\n",
            "Accuracy at epoch 760: 0.9572\n",
            "Accuracy at epoch 780: 0.9586\n",
            "Accuracy at epoch 800: 0.9605\n",
            "Accuracy at epoch 820: 0.9622\n",
            "Accuracy at epoch 840: 0.9625\n",
            "Accuracy at epoch 860: 0.9630\n",
            "Accuracy at epoch 880: 0.9639\n",
            "Accuracy at epoch 900: 0.9647\n",
            "Accuracy at epoch 920: 0.9655\n",
            "Accuracy at epoch 940: 0.9664\n",
            "Accuracy at epoch 960: 0.9672\n",
            "Accuracy at epoch 980: 0.9678\n",
            "Accuracy at epoch 1000: 0.9686\n",
            "Average accuracy: 0.8880\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    return predicted\n",
        "\n",
        "accuracies = []\n",
        "for epoch in range(checkpoint_each, epochs + 1, checkpoint_each):\n",
        "    checkpoint = torch.load(f\"checkpoint_epoch_{epoch}.pt\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    y_pred = evaluate(model, torch.from_numpy(X_test).float())\n",
        "    accuracy = accuracy_score(y_test, y_pred.cpu().numpy())\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Accuracy at epoch {epoch}: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"Average accuracy: {np.mean(accuracies):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QRGYqqT1MCP"
      },
      "source": [
        "Cargar un Epoch a la vez\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDmjhQn51OVl",
        "outputId": "13833d91-7897-4672-ad15-0d1b00baa44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using checkpoint_epoch_1000.pt: 0.9686\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    return predicted\n",
        "\n",
        "checkpoint_file = \"checkpoint_epoch_1000.pt\"\n",
        "\n",
        "checkpoint = torch.load(checkpoint_file)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "y_pred = evaluate(model, torch.from_numpy(X_test).float())\n",
        "accuracy = accuracy_score(y_test, y_pred.cpu().numpy())\n",
        "print(f\"Accuracy using {checkpoint_file}: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iiKna8V3RWd"
      },
      "source": [
        "Torchscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FKvNXDuR3RA_"
      },
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(model)\n",
        "torch.jit.save(scripted_model, 'scripted_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ojGeMqM5eEJ",
        "outputId": "85df7428-e7de-47ca-bacd-36582eb082ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9700\n"
          ]
        }
      ],
      "source": [
        "scripted_model = torch.jit.load(\"scripted_model.pt\")\n",
        "X_t = torch.from_numpy(X_test).float()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicted = model(X_test)\n",
        "        _, predicted_labels = torch.max(predicted, 1)\n",
        "        accuracy = accuracy_score(y_test, predicted_labels.numpy())\n",
        "        return accuracy\n",
        "\n",
        "test_accuracy = evaluate_model(scripted_model, X_t, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyOsGCny3h-m"
      },
      "source": [
        "ONNX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4aMzcmNh3kRp"
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(64, 10)\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYKWe_nZ4jrT",
        "outputId": "1bcba3ea-e080-4210-cb00-6fb833e8a9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ncqE2ZMW6qj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "import torch.onnx\n",
        "import onnx\n",
        "import onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMhVMdvI90s4"
      },
      "outputs": [],
      "source": [
        "D_in, H, D_out = 10, 100, 10\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DusYFZpb94Eu",
        "outputId": "2a474fdd-27b8-480a-957c-aafed3a71120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(torch.randn(64, 10))\n",
        "outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT0s4PZ0AoT7",
        "outputId": "024cd2df-f79b-4f81-b854-0fb20d15ef03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17995, 10), (17995,))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('riceClassification.csv')\n",
        "X = df.iloc[:, :10]\n",
        "Y = df.iloc[:, -1]\n",
        "\n",
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZbwuYS7Crji"
      },
      "outputs": [],
      "source": [
        "x_2 = np.array(X)\n",
        "y_2 = np.array(Y)\n",
        "\n",
        "scaler = StandardScaler().fit(x_2)\n",
        "x_2_normalized = scaler.transform(x_2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_2_normalized, y_2, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j7AkggUGLL5"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "def cross_entropy(output, target):\n",
        "    logits = output[torch.arange(len(output)), target]\n",
        "    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skpk7uxRHeC2",
        "outputId": "e3840fa3-6479-4e9b-d4c5-b47bfe23c001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/1000 Loss 0.95812\n",
            "Epoch 200/1000 Loss 0.79786\n",
            "Epoch 300/1000 Loss 0.69009\n",
            "Epoch 400/1000 Loss 0.60781\n",
            "Epoch 500/1000 Loss 0.54303\n",
            "Epoch 600/1000 Loss 0.49200\n",
            "Epoch 700/1000 Loss 0.45137\n",
            "Epoch 800/1000 Loss 0.41830\n",
            "Epoch 900/1000 Loss 0.39083\n",
            "Epoch 1000/1000 Loss 0.36760\n"
          ]
        }
      ],
      "source": [
        "X_t = torch.from_numpy(X_train).float()\n",
        "Y_t = torch.from_numpy(y_train).long()\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = SGD(model.parameters(), lr=0.3)\n",
        "epochs = 1000\n",
        "log_each = 100\n",
        "checkpoint_each = 20\n",
        "l = []\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "    y_pred = model(X_t)\n",
        "    loss = loss_fn(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % log_each == 0:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "\n",
        "    if e % checkpoint_each == 0:\n",
        "        torch.save({\n",
        "            'epoch': e,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "        }, f\"checkpoint_epoch_{e}.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_J8A2dCJNyk",
        "outputId": "1a3cd762-8db5-43f7-a7b0-94b707177d64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9649902750764101"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hipUzCMF096g"
      },
      "source": [
        "Cargar todo los checkpoints basados en los epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oui7Ws1ezwES",
        "outputId": "d1b74757-eb71-4123-a6a1-c1cb4aaabd2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy at epoch 20: 0.6238\n",
            "Accuracy at epoch 40: 0.6916\n",
            "Accuracy at epoch 60: 0.7549\n",
            "Accuracy at epoch 80: 0.7944\n",
            "Accuracy at epoch 100: 0.8194\n",
            "Accuracy at epoch 120: 0.8044\n",
            "Accuracy at epoch 140: 0.7610\n",
            "Accuracy at epoch 160: 0.8033\n",
            "Accuracy at epoch 180: 0.8122\n",
            "Accuracy at epoch 200: 0.8183\n",
            "Accuracy at epoch 220: 0.8277\n",
            "Accuracy at epoch 240: 0.8355\n",
            "Accuracy at epoch 260: 0.8433\n",
            "Accuracy at epoch 280: 0.8497\n",
            "Accuracy at epoch 300: 0.8572\n",
            "Accuracy at epoch 320: 0.8661\n",
            "Accuracy at epoch 340: 0.8733\n",
            "Accuracy at epoch 360: 0.8825\n",
            "Accuracy at epoch 380: 0.8911\n",
            "Accuracy at epoch 400: 0.8994\n",
            "Accuracy at epoch 420: 0.9086\n",
            "Accuracy at epoch 440: 0.9147\n",
            "Accuracy at epoch 460: 0.9203\n",
            "Accuracy at epoch 480: 0.9241\n",
            "Accuracy at epoch 500: 0.9283\n",
            "Accuracy at epoch 520: 0.9319\n",
            "Accuracy at epoch 540: 0.9347\n",
            "Accuracy at epoch 560: 0.9372\n",
            "Accuracy at epoch 580: 0.9400\n",
            "Accuracy at epoch 600: 0.9422\n",
            "Accuracy at epoch 620: 0.9447\n",
            "Accuracy at epoch 640: 0.9461\n",
            "Accuracy at epoch 660: 0.9483\n",
            "Accuracy at epoch 680: 0.9494\n",
            "Accuracy at epoch 700: 0.9508\n",
            "Accuracy at epoch 720: 0.9514\n",
            "Accuracy at epoch 740: 0.9530\n",
            "Accuracy at epoch 760: 0.9550\n",
            "Accuracy at epoch 780: 0.9564\n",
            "Accuracy at epoch 800: 0.9569\n",
            "Accuracy at epoch 820: 0.9580\n",
            "Accuracy at epoch 840: 0.9589\n",
            "Accuracy at epoch 860: 0.9605\n",
            "Accuracy at epoch 880: 0.9622\n",
            "Accuracy at epoch 900: 0.9628\n",
            "Accuracy at epoch 920: 0.9630\n",
            "Accuracy at epoch 940: 0.9633\n",
            "Accuracy at epoch 960: 0.9636\n",
            "Accuracy at epoch 980: 0.9644\n",
            "Accuracy at epoch 1000: 0.9650\n",
            "Average accuracy: 0.8945\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    return predicted\n",
        "\n",
        "accuracies = []\n",
        "for epoch in range(checkpoint_each, epochs + 1, checkpoint_each):\n",
        "    checkpoint = torch.load(f\"checkpoint_epoch_{epoch}.pt\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    y_pred = evaluate(model, torch.from_numpy(X_test).float())\n",
        "    accuracy = accuracy_score(y_test, y_pred.cpu().numpy())\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Accuracy at epoch {epoch}: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"Average accuracy: {np.mean(accuracies):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QRGYqqT1MCP"
      },
      "source": [
        "Cargar un Epoch a la vez\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDmjhQn51OVl",
        "outputId": "dcb9b83f-ee05-49e6-a6fb-dfb6c5b358bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy using checkpoint_epoch_1000.pt: 0.9650\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    return predicted\n",
        "\n",
        "checkpoint_file = \"checkpoint_epoch_1000.pt\"\n",
        "\n",
        "checkpoint = torch.load(checkpoint_file)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "y_pred = evaluate(model, torch.from_numpy(X_test).float())\n",
        "accuracy = accuracy_score(y_test, y_pred.cpu().numpy())\n",
        "print(f\"Accuracy using {checkpoint_file}: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iiKna8V3RWd"
      },
      "source": [
        "Torchscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKvNXDuR3RA_"
      },
      "outputs": [],
      "source": [
        "scripted_model = torch.jit.script(model)\n",
        "torch.jit.save(scripted_model, 'scripted_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ojGeMqM5eEJ",
        "outputId": "4280d83a-ea2f-4863-8282-dd1fdf811e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9650\n"
          ]
        }
      ],
      "source": [
        "scripted_model = torch.jit.load(\"scripted_model.pt\")\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicted = model(X_test)\n",
        "        _, predicted_labels = torch.max(predicted, 1)\n",
        "        accuracy = accuracy_score(y_test, predicted_labels.numpy())\n",
        "        return accuracy\n",
        "\n",
        "test_accuracy = evaluate_model(scripted_model, X_test_tensor, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyOsGCny3h-m"
      },
      "source": [
        "ONNX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aMzcmNh3kRp"
      },
      "outputs": [],
      "source": [
        "dummy_input = torch.randn(10, 10)\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

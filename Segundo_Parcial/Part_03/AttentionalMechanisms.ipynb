{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def read_file(file, reverse=False):\n",
    "    # Read the file and split into lines\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = read_file('eng-fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is an option to consider .', 'c est une possibilite a envisager .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2, \"UNK\": 3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\", 3: \"UNK\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, PAD, and UNK\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def indexesFromSentence(self, sentence):\n",
    "        return [self.word2index.get(word, self.word2index[\"UNK\"]) for word in sentence.split(' ')]\n",
    "\n",
    "    def sentenceFromIndex(self, index):\n",
    "        return [self.index2word[ix] for ix in index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filterPairs(pairs, filters, lang=0):\n",
    "    return [p for p in pairs if p[lang].startswith(filters)]\n",
    "\n",
    "def trimPairs(pairs):\n",
    "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 135842 pares de frases\n",
      "Tenemos 95170 pares de frases con longitud menor de 10\n",
      "Longitud vocabularios:\n",
      "eng 10027\n",
      "fra 16815\n",
      "['i don t want to hurt her .', 'je ne veux pas la blesser .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(file, filters=None, reverse=False):\n",
    "\n",
    "    pairs = read_file(file, reverse)\n",
    "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
    "\n",
    "    if filters is not None:\n",
    "        pairs = filterPairs(pairs, filters, int(reverse))\n",
    "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
    "\n",
    "    pairs = trimPairs(pairs)\n",
    "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang('fra')\n",
    "        output_lang = Lang('eng')\n",
    "    else:\n",
    "        input_lang = Lang('eng')\n",
    "        output_lang = Lang('fra')\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    # Print vocabulary lengths\n",
    "    print(\"Longitud vocabularios:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# Use the updated function to prepare data for English-French translation\n",
    "input_lang, output_lang, pairs = prepareData('eng-fra.txt')\n",
    "\n",
    "# Print a random pair to verify\n",
    "print(random.choice(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 2536, 3, 3, 16]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.indexesFromSentence('Owls are active at night .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jubilez', 'loucha', 'serieuse', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.sentenceFromIndex([1000, 1028, 647, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76136, 19034)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_lang, output_lang, pairs, max_length):\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.pairs = pairs\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        inputs = torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long)\n",
    "        outputs = torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n",
    "        # metemos padding a todas las frases hast a la longitud máxima\n",
    "        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.input_lang.word2index['PAD']), \\\n",
    "            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.output_lang.word2index['PAD'])\n",
    "\n",
    "# separamos datos en train-test\n",
    "train_size = len(pairs) * 80 // 100\n",
    "train = pairs[:train_size]\n",
    "test = pairs[train_size:]\n",
    "\n",
    "dataset = {\n",
    "    'train': Dataset(input_lang, output_lang, train, max_length=MAX_LENGTH),\n",
    "    'test': Dataset(input_lang, output_lang, test, max_length=MAX_LENGTH)\n",
    "}\n",
    "\n",
    "len(dataset['train']), len(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 7, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " tensor([6, 5, 2, 2, 2, 2, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence, output_sentence = dataset['train'][1]\n",
    "\n",
    "input_sentence, output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['run', '!', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
       " ['cours', '!', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False),\n",
    "}\n",
    "\n",
    "inputs, outputs = next(iter(dataloader['train']))\n",
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, input_sentences):\n",
    "        embedded = self.embedding(input_sentences)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_size=input_lang.n_words)\n",
    "encoder_outputs, encoder_hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n",
    "\n",
    "# [batch size, seq len, hidden size] \n",
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 100])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [num layers, batch size, hidden size]\n",
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        # attention\n",
    "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
    "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_words, hidden, encoder_outputs):\n",
    "        # sacamos los embeddings\n",
    "        embedded = self.embedding(input_words)\n",
    "        # calculamos los pesos de la capa de atención\n",
    "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
    "        # re-escalamos los outputs del encoder con estos pesos\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
    "        # aplicamos la capa de atención\n",
    "        output = self.attn_combine(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        # a partir de aquí, como siempre. La diferencia es que la entrada a la RNN\n",
    "        # no es directmanete el embedding sino una combinación del embedding\n",
    "        # y las salidas del encoder re-escaladas\n",
    "        output, hidden = self.gru(output.unsqueeze(1), hidden)\n",
    "        output = self.out(output.squeeze(1))\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victus\\AppData\\Local\\Temp\\ipykernel_7672\\1629649894.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16815])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = AttnDecoder(input_size=output_lang.n_words)\n",
    "decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, output_lang.n_words, (64, 1)), encoder_hidden, encoder_outputs)\n",
    "\n",
    "# [batch size, vocab size]\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 100])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [num layers, batch size, hidden size]\n",
    "decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch size, max_length]\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(encoder, decoder, dataloader, epochs=10):\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        train_loss = []\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        for batch in bar:\n",
    "            input_sentences, output_sentences = batch\n",
    "            bs = input_sentences.shape[0]\n",
    "            loss = 0\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            # obtenemos el último estado oculto del encoder\n",
    "            encoder_outputs, hidden = encoder(input_sentences)\n",
    "            # calculamos las salidas del decoder de manera recurrente\n",
    "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
    "            for i in range(output_sentences.shape[1]):\n",
    "                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "                loss += criterion(output, output_sentences[:, i].view(bs))\n",
    "                # el siguiente input será la palabra predicha\n",
    "                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
    "            # optimización\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
    "\n",
    "        val_loss = []\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            bar = tqdm(dataloader['test'])\n",
    "            for batch in bar:\n",
    "                input_sentences, output_sentences = batch\n",
    "                bs = input_sentences.shape[0]\n",
    "                loss = 0\n",
    "                # obtenemos el último estado oculto del encoder\n",
    "                encoder_outputs, hidden = encoder(input_sentences)\n",
    "                # calculamos las salidas del decoder de manera recurrente\n",
    "                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
    "                for i in range(output_sentences.shape[1]):\n",
    "                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "                    loss += criterion(output, output_sentences[:, i].view(bs))\n",
    "                    # el siguiente input será la palabra predicha\n",
    "                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
    "                val_loss.append(loss.item())\n",
    "                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1190 [00:00<?, ?it/s]C:\\Users\\victus\\AppData\\Local\\Temp\\ipykernel_7672\\1629649894.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
      "Epoch 1/30 loss 35.89282: 100%|██████████| 1190/1190 [05:26<00:00,  3.64it/s]\n",
      "Epoch 1/30 val_loss 45.34237: 100%|██████████| 75/75 [00:26<00:00,  2.78it/s]\n",
      "Epoch 2/30 loss 27.90138: 100%|██████████| 1190/1190 [05:25<00:00,  3.66it/s]\n",
      "Epoch 2/30 val_loss 41.21413: 100%|██████████| 75/75 [00:27<00:00,  2.78it/s]\n",
      "Epoch 3/30 loss 24.29465: 100%|██████████| 1190/1190 [05:24<00:00,  3.67it/s]\n",
      "Epoch 3/30 val_loss 39.52516: 100%|██████████| 75/75 [00:26<00:00,  2.78it/s]\n",
      "Epoch 4/30 loss 21.90706: 100%|██████████| 1190/1190 [05:22<00:00,  3.69it/s]\n",
      "Epoch 4/30 val_loss 38.50791: 100%|██████████| 75/75 [00:26<00:00,  2.82it/s]\n",
      "Epoch 5/30 loss 20.06954: 100%|██████████| 1190/1190 [05:22<00:00,  3.69it/s]\n",
      "Epoch 5/30 val_loss 37.89193: 100%|██████████| 75/75 [00:26<00:00,  2.82it/s]\n",
      "Epoch 6/30 loss 18.56705: 100%|██████████| 1190/1190 [30:44<00:00,  1.55s/it]   \n",
      "Epoch 6/30 val_loss 37.60164: 100%|██████████| 75/75 [00:19<00:00,  3.82it/s]\n",
      "Epoch 7/30 loss 17.30791: 100%|██████████| 1190/1190 [03:54<00:00,  5.08it/s]\n",
      "Epoch 7/30 val_loss 37.34924: 100%|██████████| 75/75 [00:19<00:00,  3.86it/s]\n",
      "Epoch 8/30 loss 16.22738: 100%|██████████| 1190/1190 [03:47<00:00,  5.24it/s]\n",
      "Epoch 8/30 val_loss 37.54803: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 9/30 loss 15.30305: 100%|██████████| 1190/1190 [03:46<00:00,  5.25it/s]\n",
      "Epoch 9/30 val_loss 37.46303: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 10/30 loss 14.48268: 100%|██████████| 1190/1190 [03:46<00:00,  5.26it/s]\n",
      "Epoch 10/30 val_loss 37.65195: 100%|██████████| 75/75 [00:19<00:00,  3.86it/s]\n",
      "Epoch 11/30 loss 13.76220: 100%|██████████| 1190/1190 [03:46<00:00,  5.25it/s]\n",
      "Epoch 11/30 val_loss 37.95605: 100%|██████████| 75/75 [00:19<00:00,  3.85it/s]\n",
      "Epoch 12/30 loss 13.13649: 100%|██████████| 1190/1190 [03:47<00:00,  5.24it/s]\n",
      "Epoch 12/30 val_loss 38.21520: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 13/30 loss 12.58448: 100%|██████████| 1190/1190 [03:49<00:00,  5.18it/s]\n",
      "Epoch 13/30 val_loss 38.64275: 100%|██████████| 75/75 [00:19<00:00,  3.86it/s]\n",
      "Epoch 14/30 loss 12.08029: 100%|██████████| 1190/1190 [03:48<00:00,  5.20it/s]\n",
      "Epoch 14/30 val_loss 38.94465: 100%|██████████| 75/75 [00:19<00:00,  3.85it/s]\n",
      "Epoch 15/30 loss 11.64601: 100%|██████████| 1190/1190 [03:51<00:00,  5.14it/s]\n",
      "Epoch 15/30 val_loss 39.09898: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 16/30 loss 11.26068: 100%|██████████| 1190/1190 [03:49<00:00,  5.19it/s]\n",
      "Epoch 16/30 val_loss 39.73817: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 17/30 loss 10.89770: 100%|██████████| 1190/1190 [03:50<00:00,  5.17it/s]\n",
      "Epoch 17/30 val_loss 39.83490: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 18/30 loss 10.56261: 100%|██████████| 1190/1190 [03:50<00:00,  5.17it/s]\n",
      "Epoch 18/30 val_loss 40.16239: 100%|██████████| 75/75 [00:19<00:00,  3.89it/s]\n",
      "Epoch 19/30 loss 10.26630: 100%|██████████| 1190/1190 [03:50<00:00,  5.16it/s]\n",
      "Epoch 19/30 val_loss 40.57816: 100%|██████████| 75/75 [00:19<00:00,  3.83it/s]\n",
      "Epoch 20/30 loss 9.99065: 100%|██████████| 1190/1190 [03:51<00:00,  5.14it/s]\n",
      "Epoch 20/30 val_loss 40.72793: 100%|██████████| 75/75 [00:19<00:00,  3.87it/s]\n",
      "Epoch 21/30 loss 9.74532: 100%|██████████| 1190/1190 [03:54<00:00,  5.08it/s]\n",
      "Epoch 21/30 val_loss 41.17679: 100%|██████████| 75/75 [00:19<00:00,  3.85it/s]\n",
      "Epoch 22/30 loss 9.51623: 100%|██████████| 1190/1190 [03:51<00:00,  5.14it/s]\n",
      "Epoch 22/30 val_loss 41.52318: 100%|██████████| 75/75 [00:19<00:00,  3.89it/s]\n",
      "Epoch 23/30 loss 9.31577: 100%|██████████| 1190/1190 [03:50<00:00,  5.16it/s]\n",
      "Epoch 23/30 val_loss 41.75055: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 24/30 loss 9.10770: 100%|██████████| 1190/1190 [03:50<00:00,  5.17it/s]\n",
      "Epoch 24/30 val_loss 42.09579: 100%|██████████| 75/75 [00:19<00:00,  3.89it/s]\n",
      "Epoch 25/30 loss 8.94232: 100%|██████████| 1190/1190 [03:51<00:00,  5.13it/s]\n",
      "Epoch 25/30 val_loss 42.48210: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 26/30 loss 8.75159: 100%|██████████| 1190/1190 [03:52<00:00,  5.12it/s]\n",
      "Epoch 26/30 val_loss 42.50978: 100%|██████████| 75/75 [00:19<00:00,  3.89it/s]\n",
      "Epoch 27/30 loss 8.59789: 100%|██████████| 1190/1190 [03:54<00:00,  5.08it/s]\n",
      "Epoch 27/30 val_loss 43.09775: 100%|██████████| 75/75 [00:19<00:00,  3.85it/s]\n",
      "Epoch 28/30 loss 8.45145: 100%|██████████| 1190/1190 [03:50<00:00,  5.15it/s]\n",
      "Epoch 28/30 val_loss 43.24332: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n",
      "Epoch 29/30 loss 8.30578: 100%|██████████| 1190/1190 [03:50<00:00,  5.16it/s]\n",
      "Epoch 29/30 val_loss 43.87778: 100%|██████████| 75/75 [00:19<00:00,  3.89it/s]\n",
      "Epoch 30/30 loss 8.17003: 100%|██████████| 1190/1190 [03:50<00:00,  5.16it/s]\n",
      "Epoch 30/30 val_loss 43.83965: 100%|██████████| 75/75 [00:19<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "fit(encoder, decoder, dataloader, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['is', 'he', 'at', 'home', '?', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
       " ['est', 'il', 'chez', 'lui', '?', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence, output_sentence = dataset['train'][5000]\n",
    "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "    # obtener el último estado oculto del encoder\n",
    "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
    "    # calcular las salidas del decoder de manera recurrente\n",
    "    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
    "    # iterar hasta que el decoder nos de el token <eos> o hasta que el max length sea alcanzado\n",
    "    outputs = []\n",
    "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "    i = 0\n",
    "    while True:\n",
    "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "        if i < MAX_LENGTH:\n",
    "            decoder_attentions[i] = attn_weights.data\n",
    "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
    "        outputs.append(decoder_input.cpu().item())\n",
    "        if decoder_input.item() == output_lang.word2index['EOS'] or i >= MAX_LENGTH - 1:\n",
    "            break\n",
    "        i += 1\n",
    "    return output_lang.sentenceFromIndex(outputs), decoder_attentions[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victus\\AppData\\Local\\Temp\\ipykernel_7672\\1629649894.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['est', 'il', 'a', 'la', 'maison', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attn = predict(input_sentence)\n",
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    try:\n",
    "        lim1 = input_sentence.index('EOS') + 1\n",
    "    except ValueError:\n",
    "        lim1 = len(input_sentence)\n",
    "\n",
    "    try:\n",
    "        lim2 = output_words.index('EOS') + 1\n",
    "    except ValueError:\n",
    "        lim2 = len(output_words)\n",
    "\n",
    "    fig = plt.figure(dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
    "    ax.set_yticklabels([' '] + output_words[:lim2])\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victus\\AppData\\Local\\Temp\\ipykernel_7672\\2628931795.py:18: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
      "C:\\Users\\victus\\AppData\\Local\\Temp\\ipykernel_7672\\2628931795.py:19: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([' '] + output_words[:lim2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AttentionalENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

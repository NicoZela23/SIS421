{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccion de LLM\n",
    "\n",
    "El LLm escogido para ejecucion y posterior fine tunnig es Gemini 1.0 Pro 001 mismo que fue entrenado para ser un asistente en la modificacion de teclados mecanicos, esta teniendo informacion especifica tanto de productos como de funciones de nicho segun el contexto de la modificacion de teclados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias\n",
    "Esta ejecucion e instalacion de librerias junto con la configuracion especifica esta dise√±ada para poder ser ejecutada en este entorno local y en todos los posibles 500 entornos de posible ejecucion asignados via permiso de la suite de Google. Dada la limitacion del uso del API la forma de ejecucion y configuracion usando Colab es distinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "import google.generativeai as genai\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las credenciales tanto del APi como los permisos del usuario almacenados en un secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/generative-language.retriever']\n",
    "\n",
    "def load_creds():\n",
    "    \"\"\"Converts `client_secret.json` to a credential object.\n",
    "\n",
    "    This function caches the generated tokens to minimize the use of the\n",
    "    consent screen.\n",
    "    \"\"\"\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secret.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "    return creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el siguiente test para confimar que tenemos los modelos cargados correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available base models: ['models/chat-bison-001', 'models/text-bison-001', 'models/embedding-gecko-001', 'models/gemini-1.0-pro', 'models/gemini-1.0-pro-001', 'models/gemini-1.0-pro-latest', 'models/gemini-1.0-pro-vision-latest', 'models/gemini-1.5-flash', 'models/gemini-1.5-flash-001', 'models/gemini-1.5-flash-latest', 'models/gemini-1.5-pro', 'models/gemini-1.5-pro-001', 'models/gemini-1.5-pro-latest', 'models/gemini-pro', 'models/gemini-pro-vision', 'models/embedding-001', 'models/text-embedding-004', 'models/aqa']\n"
     ]
    }
   ],
   "source": [
    "creds = load_creds()\n",
    "\n",
    "genai.configure(credentials=creds)\n",
    "\n",
    "print()\n",
    "print('Available base models:', [m.name for m in genai.list_models()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo uso de las credenciales y mediante un request al API hacemos uso del mismo con la definicion de sus parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It depends, does it shine like a christmas tree?\n"
     ]
    }
   ],
   "source": [
    "creds = load_creds()\n",
    "\n",
    "genai.configure(credentials=creds)\n",
    "\n",
    "# Set up the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0.15,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 0,\n",
    "  \"max_output_tokens\": 8192,\n",
    "}\n",
    "\n",
    "safety_settings = [\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"tunedModels/mykeyboardqa-kalkoww5l19h\",\n",
    "                              generation_config=generation_config,\n",
    "                              safety_settings=safety_settings)\n",
    "\n",
    "prompt_parts = [\n",
    "  \"input: Is my keyboard RGB?\",\n",
    "  \"output: \",\n",
    "]\n",
    "\n",
    "response = model.generate_content(prompt_parts)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
